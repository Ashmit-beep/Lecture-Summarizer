{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7627e9fe-d543-402c-b6e2-84121157ef06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: \n",
      " CNNs leverage three key ideas: local receptive fields, shared weights, and pooling layers. CNNs drastically reduce the number of parameters and help recognize features regardless of where they appear. By the end of this lecture, you should understand how each component works together.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Both `max_new_tokens` (=256) and `max_length`(=40) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Quiz Questions: \n",
      "1. question: What do you want to know about CNNs?\n",
      "2. question: What do you want to learn about CNNs?\n",
      "3. question: How do you generate questions from ?\n",
      "4. question: How do you generate questions from :\n",
      "5. question: What do you want to know about CNN?\n"
     ]
    }
   ],
   "source": [
    "transcript = \"Alright, so today we’re diving into convolutional neural networks, or CNNs. Unlike traditional fully connected networks, CNNs leverage three key ideas: local receptive fields, shared weights, and pooling layers. First, with local receptive fields, each neuron only looks at a small region of the input image—this lets the network detect simple features like edges or corners. Then, by sharing the same filter weights across different positions, CNNs drastically reduce the number of parameters and help recognize features regardless of where they appear. After convolution, we apply a non-linear activation—usually ReLU—to introduce non-linearity, which lets the network learn more complex patterns. Next comes pooling, often max-pooling, which downsamples the feature maps to make the representation more compact and invariant to small translations. Finally, we stack several convolution and pooling layers to build a deep hierarchy, ending with fully connected layers for classification. By the end of this lecture, you should understand how each component works together to extract spatial hierarchies of features from images.\"\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "## Code for Summary of transcript\n",
    "summarizer = pipeline(\"summarization\", model = \"facebook/bart-large-cnn\")\n",
    "summary = summarizer(\n",
    "    transcript,\n",
    "    max_length = 100,\n",
    "    min_length = 15,\n",
    "    do_sample = False\n",
    ")\n",
    "print(\"Summary: \\n\", summary[0] ['summary_text'])\n",
    "\n",
    "## Code for Question Generation\n",
    "qg = pipeline(\"text2text-generation\",\n",
    "            model = \"mrm8488/t5-base-finetuned-question-generation-ap\",\n",
    "            device = -1\n",
    "            )\n",
    "qg_input_text = \"Generate Questions from :\" + transcript\n",
    "\n",
    "qg_output = qg(\n",
    "    qg_input_text,\n",
    "    num_beams = 5,\n",
    "    num_return_sequences = 5,\n",
    "    max_length = 40,\n",
    "    min_length = 10,\n",
    "    do_sample = False\n",
    ")\n",
    "\n",
    "print(\"\\n Quiz Questions: \")\n",
    "for idx, out in enumerate(qg_output,1):\n",
    "    print(f\"{idx}. {out['generated_text']}\")\n",
    "    \n",
    "## For using OpenAI API\n",
    "# import openai\n",
    "# openai.api_key = \"\"\n",
    "# prompt = (\"Generate five quiz questions with answers based on the following transcript: \\n\"\n",
    "#         f\"{transcript}\"\n",
    "#          )\n",
    "# response = openAI.chatCompletion.create(\n",
    "#     model = \"gpt-4o\",\n",
    "#     messages = [{\"role\": \"user\", \"content\": prompt}],\n",
    "#     max_tokens = 300\n",
    "# )\n",
    "\n",
    "##print(\"Quiz Questions: \\n\", response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a37de9e-4731-4ac1-9d55-4875a33b1c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
